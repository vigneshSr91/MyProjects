{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Keyword spotting from Speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import relevant packages/modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import os\r\n",
    "import pkg_resources\r\n",
    "from pydub import AudioSegment\r\n",
    "from pydub.silence import split_on_silence\r\n",
    "import speech_recognition as sr\r\n",
    "from symspellpy import SymSpell, Verbosity\r\n",
    "from flashtext import KeywordProcessor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# init variables and clear slice files\r\n",
    "Speech = None\r\n",
    "slices = None\r\n",
    "slice_filenames=[]\r\n",
    "\r\n",
    "if os.path.isdir('./speech-slices'):\r\n",
    "    fileList = os.listdir('./speech-slices')\r\n",
    "    for doc in fileList:\r\n",
    "        os.remove(os.path.join('./speech-slices',doc))\r\n",
    "\r\n",
    "# open the audio file using pydub\r\n",
    "path = os.path.join(os.curdir,'eng.wav')\r\n",
    "Speech = AudioSegment.from_wav(path)\r\n",
    "\r\n",
    "# Split the speech file into slices where a gap of atleast 500 milliseconds\r\n",
    "slices = split_on_silence(Speech,\r\n",
    "    min_silence_len=500,\r\n",
    "    silence_thresh=Speech.dBFS,\r\n",
    "    keep_silence=500)\r\n",
    "\r\n",
    "# Create a Folder to store the split slices of audio files\r\n",
    "if not os.path.isdir('./speech-slices'):\r\n",
    "    os.mkdir('./speech-slices')\r\n",
    "\r\n",
    "for i, slice in enumerate(slices,start=1):\r\n",
    "    slice_filename = os.path.join('./speech-slices',f'speech_slice{i}.wav')\r\n",
    "    slice.export(slice_filename,format=\"wav\")\r\n",
    "    slice_filenames.append(slice_filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Initialize variables\r\n",
    "asr = sr.Recognizer()\r\n",
    "text_corpus=\"\"\r\n",
    "textMap={}\r\n",
    "\r\n",
    "# convert the audio slices to text\r\n",
    "for filename in slice_filenames:\r\n",
    "    with sr.AudioFile(filename) as source:\r\n",
    "        audio_source = asr.record(source)\r\n",
    "        try:\r\n",
    "            text=asr.recognize_google(audio_source)\r\n",
    "        except  sr.UnknownValueError as e:\r\n",
    "            print(\"Error Occurred: \", str(e))\r\n",
    "        else:\r\n",
    "            text=f\"{text.capitalize()}. \"\r\n",
    "            text_corpus += text\r\n",
    "            textMap[filename] = text\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error Occurred:  \n",
      "Error Occurred:  \n",
      "Error Occurred:  \n",
      "Error Occurred:  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(textMap)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'./speech-slices\\\\speech_slice2.wav': 'Do you like manchester united. ', './speech-slices\\\\speech_slice3.wav': 'What is uk. ', './speech-slices\\\\speech_slice4.wav': 'I having fun. ', './speech-slices\\\\speech_slice5.wav': 'Yeah. ', './speech-slices\\\\speech_slice7.wav': 'What do you like the bass. ', './speech-slices\\\\speech_slice8.wav': 'Devika. ', './speech-slices\\\\speech_slice9.wav': 'The people here are. ', './speech-slices\\\\speech_slice10.wav': 'You like this. ', './speech-slices\\\\speech_slice11.wav': 'Yeah. ', './speech-slices\\\\speech_slice12.wav': 'Where is great. ', './speech-slices\\\\speech_slice13.wav': 'Is this field too spicy for you. ', './speech-slices\\\\speech_slice15.wav': 'I love. ', './speech-slices\\\\speech_slice17.wav': 'Everyday. ', './speech-slices\\\\speech_slice18.wav': 'How much longer you stay. ', './speech-slices\\\\speech_slice19.wav': 'When you go. '}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# perform spell correction\r\n",
    "spellCorrectedTxtMap={}\r\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\r\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy\",\"frequency_dictionary_en_82_765.txt\")\r\n",
    "bigram_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\r\n",
    "\r\n",
    "\r\n",
    "for val in textMap.keys():\r\n",
    "    text = textMap[val]\r\n",
    "    sym_spell.load_dictionary(dictionary_path,term_index=0,count_index=1)\r\n",
    "    sym_spell.load_bigram_dictionary(bigram_path,term_index=0,count_index=2)\r\n",
    "\r\n",
    "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\r\n",
    "\r\n",
    "    sent=[]\r\n",
    "    for suggestion in suggestions:\r\n",
    "        sent.append(suggestion)\r\n",
    "    \r\n",
    "    predicted_sentence = str(sent[0].term)\r\n",
    "    splitter = predicted_sentence\r\n",
    "\r\n",
    "    spellCorrectedTxtMap[val] = splitter\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#print(spellCorrectedTxtMap)\r\n",
    "\r\n",
    "for val in spellCorrectedTxtMap.keys():\r\n",
    "    print(spellCorrectedTxtMap[val])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "do you like manchester united\n",
      "what is us\n",
      "i having fun\n",
      "yeah\n",
      "what do you like the bass\n",
      "devi a\n",
      "the people here are\n",
      "you like this\n",
      "yeah\n",
      "where is great\n",
      "is this field too spicy for you\n",
      "i love\n",
      "everyday\n",
      "how much longer you stay\n",
      "when you go\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class AddMultiKeywords:\r\n",
    "\r\n",
    "    def __init__(self, text, keyword_dict):\r\n",
    "        self.text = text\r\n",
    "        self.keyword_dict = keyword_dict\r\n",
    "\r\n",
    "    def addkey(self):\r\n",
    "        keyword_processor = KeywordProcessor()\r\n",
    "        keyword_processor.add_keywords_from_dict(self.keyword_dict)\r\n",
    "        extractedKeyword = keyword_processor.extract_keywords(self.text)\r\n",
    "        return extractedKeyword"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "extractedKeywordMap = {}\r\n",
    "\r\n",
    "for val in textMap.keys():\r\n",
    "    adding = AddMultiKeywords(textMap[val],\r\n",
    "                            {\"place\": [\"england\"],\r\n",
    "                            \"team\": [\"manchester united\"],\r\n",
    "                            \"game\": [\"football\"] } )\r\n",
    "    result = adding.addkey()\r\n",
    "    extractedKeywordMap[val] = result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print(extractedKeywordMap)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'./speech-slices\\\\speech_slice2.wav': ['team'], './speech-slices\\\\speech_slice3.wav': [], './speech-slices\\\\speech_slice4.wav': [], './speech-slices\\\\speech_slice5.wav': [], './speech-slices\\\\speech_slice7.wav': [], './speech-slices\\\\speech_slice8.wav': [], './speech-slices\\\\speech_slice9.wav': [], './speech-slices\\\\speech_slice10.wav': [], './speech-slices\\\\speech_slice11.wav': [], './speech-slices\\\\speech_slice12.wav': [], './speech-slices\\\\speech_slice13.wav': [], './speech-slices\\\\speech_slice15.wav': [], './speech-slices\\\\speech_slice17.wav': [], './speech-slices\\\\speech_slice18.wav': [], './speech-slices\\\\speech_slice19.wav': []}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "adb4ca985ed9a3cb7f38b00661ba9f6c8f4ea72e7212f13ee19c80eee02589bd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}